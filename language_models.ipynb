{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "A5ykFe3GXJ9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1958d01-2848-4efc-ed24-af906f4bc9d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using the latest cached version of the dataset since medalpaca/medical_meadow_medical_flashcards couldn't be found on the Hugging Face Hub\n",
            "Found the latest cached dataset configuration 'default' at /home/suuper/.cache/huggingface/datasets/medalpaca___medical_meadow_medical_flashcards/default/0.0.0/7597b32036d67c731cb91bae4f49717fcfe5d5f0 (last modified on Thu Jan  2 11:02:51 2025).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Structure of data:  DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['input', 'output', 'instruction'],\n",
            "        num_rows: 33955\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"medalpaca/medical_meadow_medical_flashcards\")\n",
        "print('Structure of data: ', ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data is a dictionary ```train``` as the key and another dictionary ```Dataset```  as the value, the keys of this dictinoary are ```features``` and ```num_rows```, features being one of the ```input```, ```output```, or ```instruction```.\n",
        "\n",
        "The ```num_rows``` suggests that there are 33955 questions and answers with instructions respectively.\n",
        "\n",
        "Let us have a look at how each one of these are:"
      ],
      "metadata": {
        "id": "qSUwwtanf6O8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Input :', ds['train']['input'][0])\n",
        "print(f'Output :', ds['train']['output'][0])\n",
        "print(f'Instruction :', ds['train']['instruction'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foiD3SR3gRd8",
        "outputId": "509900aa-6396-4f98-8afb-53fb1c34dd82"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : What is the relationship between very low Mg2+ levels, PTH levels, and Ca2+ levels?\n",
            "Output : Very low Mg2+ levels correspond to low PTH levels which in turn results in low Ca2+ levels.\n",
            "Instruction : Answer this question truthfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ```input```'s are questions,\n",
        "\n",
        "The ```output```'s are answers and,\n",
        "\n",
        "The ```instruction```'s are the instructions to answer the questions."
      ],
      "metadata": {
        "id": "MaBPHcJkh6cU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lowercasing the text, tokenizing based on spaces to prepare the text for training."
      ],
      "metadata": {
        "id": "ko2YYxtyjdho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "\n",
        "tokenized_sentences = [re.sub('\\W', ' ', sentence).lower().split() for sentence in ds['train']['output']]\n",
        "#\\W removes the non word characters thereby removing the '+','/','-' that could be good to keep\n",
        "for i in tokenized_sentences[:5]:\n",
        "  print(i)\n",
        "\n",
        "print(f'Minimum sentence len: ', min([len(i)for i in tokenized_sentences]))\n",
        "print(f'Maximum sentence len: ', max([len(i)for i in tokenized_sentences]))\n",
        "print(f'Average sentence len: ', np.mean([len(i)for i in tokenized_sentences]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rETmU3C1iQap",
        "outputId": "f2ba15a2-d9da-4289-a063-7ecd4b71a78a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['very', 'low', 'mg2', 'levels', 'correspond', 'to', 'low', 'pth', 'levels', 'which', 'in', 'turn', 'results', 'in', 'low', 'ca2', 'levels']\n",
            "['low', 'estradiol', 'production', 'leads', 'to', 'genitourinary', 'syndrome', 'of', 'menopause', 'atrophic', 'vaginitis']\n",
            "['low', 'rem', 'sleep', 'latency', 'and', 'experiencing', 'hallucinations', 'sleep', 'paralysis', 'suggests', 'narcolepsy']\n",
            "['pth', 'independent', 'hypercalcemia', 'which', 'can', 'be', 'caused', 'by', 'cancer', 'granulomatous', 'disease', 'or', 'vitamin', 'd', 'intoxication']\n",
            "['the', 'level', 'of', 'anti', 'm√ºllerian', 'hormone', 'is', 'directly', 'related', 'to', 'ovarian', 'reserve', 'a', 'lower', 'level', 'indicates', 'a', 'lower', 'ovarian', 'reserve']\n",
            "Minimum sentence len:  0\n",
            "Maximum sentence len:  247\n",
            "Average sentence len:  54.24835812104256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now want to train the Word2Vec on the ```outputs```."
      ],
      "metadata": {
        "id": "e0Az8VgTnsdU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.word2vec import Word2Vec\n",
        "\n",
        "model = Word2Vec(tokenized_sentences, vector_size=100, min_count=2, window=10)\n",
        "print(f'Learnt vectors: ',len(model.wv))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieXfOgnFn2Tr",
        "outputId": "3bca376c-4a80-489b-93d2-f9f59d713d30"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learnt vectors:  17679\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some things to try,\n",
        "\n",
        "try different terms\n",
        "\n",
        "most similar words"
      ],
      "metadata": {
        "id": "12r2ck8T0yPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# term = 'sickness'\n",
        "# term = 'fever'\n",
        "# term = 'cure'\n",
        "term = 'drugs'\n",
        "\n",
        "sims = model.wv.most_similar(term, topn=5)\n",
        "sims"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjMOrfOA1qBA",
        "outputId": "a50755bd-48fc-40f7-9969-26d3caf226ec"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('agents', 0.8332918882369995),\n",
              " ('inhibitors', 0.7792587280273438),\n",
              " ('drug', 0.7069075703620911),\n",
              " ('medications', 0.6999640464782715),\n",
              " ('heroin', 0.6793468594551086)]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ]
}